\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath} 
\newtheorem{lemma}{lemma}
\usepackage{geometry}
\geometry{margin=1in}
\title{Board Work for Lecture 7}
\author{Jacob Kohlhepp}
\date{\today}

\begin{document}

\maketitle


\section{Relative Performance Evaluation}

Let's begin by deriving the worker's certainty equivalent for a wage given by $w(y_1, y_2)=\alpha + \beta (y_1-\gamma y_2)$. We will apply our certainty equivalent formula:
\[d = \mu -r \frac{\sigma^2}{2}\]
where $\mu=E[w(y_1, y_2)]$, $\sigma^2=Var[w(y_1, y_2)]$. The mean of the wage is:
\begin{align}
    E[w(y_1, y_2)] &= E[\alpha + \beta (Y_1-\gamma Y_2)]\\
    &= \alpha +\beta E[Y_1-\gamma Y_2]\\
    &= \alpha +\beta E[e_1+v_1 + v_s-\gamma (e_2+v_2+v_s)]\\
    &= \alpha +\beta (e_1-\gamma e_2)\\
\end{align}
The variance is:
\begin{align*}
    Var[w(y_1, y_2)] &= Var[\alpha + \beta (Y_1-\gamma Y_2)]\\
    &= Var[\alpha]  + Var[\beta (Y_1-\gamma Y_2)]\\
     &= 0 + Var[\beta (Y_1-\gamma Y_2)]\\
    &= \beta^2 Var[Y_1-\gamma Y_2]\\
    &= \beta^2 Var[e_1+v_1 + v_s-\gamma (e_2+v_2+v_s)]\\
    &= \beta^2 Var[v_1 + v_s-\gamma (v_2+v_s)]\\
    &= \beta^2 Var[v_1 + (1-\gamma )v_s-\gamma v_2]\\
    &= \beta^2 ( Var[v_1]+ Var[ (1-\gamma )v_s]+Var[\gamma v_2])\\
    &= \beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )\\
\end{align*}
We can now plug this into the certainty equivalent formula to get the worker's incentives:
\[d(w)=\alpha +\beta (e_1-\gamma e_2) -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2}\]
Consider the worker choosing effort for a fixed wage scheme. We focus on worker 1, but the analysis is the same either way. Worker 1 solves:
\[\max_{e_1} d(w)-c(e_1)=\max_{e_1} \alpha +\beta (e_1-\gamma e_2) -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e)\]
Effort does not impact the middle term, and we have the normal condition: $\beta = c'(e_1)$. This proves that $\gamma$ does not directly impact the worker's choice of effort. It does however impact the risk the worker takes on. To see this notice the term $r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2}$. This term enters into the worker's utility negatively. By increasing $\gamma$, the firm shifts weight from $\sigma_s^2$ to $\sigma^2_2$. Can someone give an intuition for this? What does this intuitively mean?

The worker accepts the wage scheme if:
\[u(accept) = \alpha +\beta (e_1-\gamma e_2) -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 ) \geq \bar u\]
The firm sets $\alpha$ as low as it can subject to the worker accepting. This amounts to making the last line an equality:

\[ \alpha +\beta (e_1-\gamma e_2) -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 ) =\bar u\]
Solving for $\alpha$:

\[ \alpha =\bar u-\beta (e_1-\gamma e_2) +r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} +c(e_1 )\]
Now we plug this into the firm's profit, along with the fact that $\beta=c'(e_1)$:

\begin{align*}
    \pi&= E[y_1-w_1]\\
    &= E[e_1+v_1- \beta (e_1+v_1+v_s-\gamma (e_2+v_2+v_s )) -\alpha ]\\
    &= e_1 - \beta (e_1-\gamma e_2)  -\alpha \\
    &= e_1 -\beta (e_1-\gamma e_2)-\bar u+\beta (e_1-\gamma e_2) -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 )\\
    &= e_1 -\bar u -r \frac{\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 )\\
    &= e_1 -\bar u -r \frac{[c'(e_1)]^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 )
\end{align*}
As before, the firm maximizes this expression. 
\[\max_{e_1, \gamma} e_1 -\bar u -r \frac{[c'(e_1)]^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 )\]
Unlike before, notice that the firm has two objects it can control: effort and $\gamma$. We need to take two FOCs. let's start with $e_1$ because it is more familiar:
\[[e_1]: 1 - c'(e_1) -r ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )c'(e_1)c''(e_1)=0\]

Simplifying:
\[ 1 = c'(e_1)\bigg (1+r  ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )c''(e_1) \bigg )\]
\[ \frac{1}{1+r  ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )c''(e_1)} = c'(e_1)=\beta_{rel}\]
If we squint at this we will see this looks just like our normal expression, but with more ``variance-related" terms. However, we are not done. The firm also gets to choose $\gamma$. We need to go all the way back to the profit expression.
\[\max_{e_1, \gamma} e_1 -\bar u -r \frac{\beta(e_1)^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )}{2} -c(e_1 )\]

Before taking the FOC, notice that only the big variance term depends on $\gamma$, and even further, only the inside part of that expression depends on it. Thus we can zoom in on that part of the profit expression. The FOC for $\gamma$ is:
\[[\gamma]: -\frac{r}{2} \bigg ( -2(1-\gamma) \sigma^2_s + 2\gamma \sigma_2^2 \bigg )=0 \]
Simplifying:
\[  (1-\gamma) \sigma^2_s - \gamma \sigma_2^2 =0 \]
\[  -\sigma^2_s\gamma  - \sigma_2^2\gamma  =-\sigma^2_s \leftrightarrow \gamma (-\sigma^2_s -\sigma_2^2)= -\sigma^2_s\]
\[ \gamma_{rel}= \frac{-\sigma^2_s}{-\sigma^2_s-\sigma_2^2}= \frac{\sigma^2_s}{\sigma^2_s+\sigma_2^2}\]

% % commented out this shortcut because it caused more confusion than it helps.
% \section{A Simpler Way}

% This was a lot of work. I want to mention a trick that could have helped us obtain the answer faster. Let's look at the worker's wage again:

% \begin{align*}
%     w(y_1, y_2)&=\alpha + \beta (Y_1 - \gamma Y_2)\\
%     &= \alpha + \beta [e_1+v_s + v_1 - \gamma (e_2+v_s + v_2)]\\
%     &= \alpha + \beta [e_1- \gamma e_2 +(1-\gamma)v_s + v_1 -\gamma v_2)]\\
%     &= \alpha + \beta e_1- \beta \gamma e_2 +\beta (1-\gamma)v_s + \beta v_1 -\beta \gamma v_2\\
%     &= \alpha+\beta  [ e_1+\underbrace{ -\gamma e_2+(1-\gamma)v_s + v_1 - \gamma v_2}_{\text{call this $\epsilon_{TOTAL}$}}]\\
%     &=\alpha +\beta [e_1 + \epsilon_{TOTAL}]\\
%     &= w(y) \text{ (From the performance pay lecture})
% \end{align*}

% So we notice that by relabeling things, relative performance pay is essentially just performance pay with a``new" nosie term which we call $\epsilon_{TOTAL}$. What are the properties of this noise term? Well, because 
% $\epsilon_{TOTAL}=-\gamma e_2+(1-\gamma)v_s + v_1 - \gamma v_2$, we know it is just the sum of a constant and a linear combination of normal random variables with mean 0. Therefore we know that $\epsilon_{TOTAL}\sim N(-\gamma e_2, \sigma^2_{TOTAL})$. We can compute its variance directly using the properties of variance (and the fact that all of the $v$ variables are independent):
% \[\sigma_{TOTAL}^2=Var(\epsilon_{TOTAL})=Var(-\gamma e_2+(1-\gamma)v_s + v_1 - \gamma v_2) = (1-\gamma)^2 \sigma^2_s + \sigma^2_1 +\gamma^2 \sigma^2_2\]

% If we apply our theorem from Lecture 4: performance Pay, we know that the profit-maximizing bonus is given by:

% \[\beta_P = \frac{1}{1+r\sigma^2c''(e_p)}\]

% If $\gamma$ is fixed, then we can just plug in $\sigma^2=\sigma^2_{TOTAL}$, to get that optimal $\beta$ satisfies:

% \[\beta_{rel} = \frac{1}{1+rc''(e_{rel}) [(1-\gamma)^2 \sigma^2_s + \sigma^2_1 +\gamma^2 \sigma^2_2]}\]

% Now, we notice two things. First, $\gamma$ does not impact effort, because it only impacts the variance of the wage from the worker's perspective. In other words, we still have $\beta=c'(e)$. Second, $\gamma$ does shift the wage around, but this does not impact the firm because it can just account for the shifts by also changing base pay $\alpha$. Therefore, the ONLY important role of $\gamma$ is it's impact on variance.

% From Lecture 5, we know that the risk-incentive trade-off implies that greater risk reduces profit. Therefore the firm wants to choose $\gamma$ to minimize the risk it places on the worker. Thus the optimal $\gamma$ can be obtained this way:

% \[\min_{\gamma} Var(w_1(y_1, y_2))=\min_{\gamma}\beta^2 ( \sigma_1^2+ (1-\gamma)^2\sigma_s^2 +\gamma^2 \sigma_2^2 )\]
% The FOC is:
% \[[\gamma]: \beta^2 (-2(1-\gamma)\sigma_s^2 +2\gamma \sigma_2^2 )=0\]
% Solving:
% \[ (-(1-\gamma)\sigma_s^2 +\gamma \sigma_2^2 )=0\]
% \[ \gamma\sigma_s^2 +\gamma \sigma_2^2 =\sigma_s^2\]
% \[\gamma_{rel} = \frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2}\]


% How does relative performance this impact effort and output?

% \[e_{rel}=\beta_{rel} = \frac{1}{1+r \sigma_{TOTAL}^2c''(e_{rel})} \]
% where:$\sigma_{TOTAL}^2=\sigma_1^2 + \gamma^2 \sigma^2_2 + (1-\gamma)^2\sigma_s^2 $. Notice that as $\sigma^2_{TOTAL}$ rises, incentives and effort fall. It is also true that profit falls (you can show this as an exercise). If we plug in $\gamma_{rel}$:
% \[\sigma_{TOTAL}^2=\sigma_1^2 + \bigg ( \frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2} \bigg )^2 \sigma^2_2 + \bigg (1- \frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2} \bigg )^2\sigma_s^2 =\sigma^2_1 + \frac{\sigma^2_2}{\sigma^2_2+\sigma^2_s}\sigma^2_s\leq  Var(v_s+v_1)=\sigma^2_s+\sigma^2_1   \]

% where $Var(v_s+v_1)$ is exactly the risk the worker is exposed to without relative performance pay, that is when $\gamma=0$. Thus incentives, effort and profit are higher with relative performance pay.

\section{Informativeness Principle}


We can actually use the ideas from relative performance evaluation to ask a more general question. Suppose that $y_2$ is not necessarily the performance of another worker, but rather some piece of data. We wish to understand whether it should be incorporated in the wage. Formally, if the wage is given by:
\[w(y_1, y_2)= \alpha+\beta y_1 + b y_2 \]
then using the information is setting $b\neq 0$. We can easly just do a change of variables, and define $b= -\beta \gamma$, and we are back to our old setup:
\[w(y_1, y_2)= \alpha+\beta y_1 -\beta \gamma y_2 = \alpha +\beta (y_1-\gamma y_2) \]

We now from the work we have done already that the optimal $\beta$ is positive because:
\[\beta_{rel} = \frac{1}{1+r \sigma^2_{TOTAL} c''(e_{rel})}>0 \]
We also know that the optimal $\gamma$ is given by:
\[\gamma_{rel} = \frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2} >0\]
Therefore, $b\neq 0$ if and only if $\gamma_{rel}>0$, which occurs whenever $\frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2}>0$. What does this mean? $\sigma^2_s$ is the variance of the shared component of $y_1, y_2$. $\sigma_s^2+\sigma_2^2$ is the total variance of $y_2$. Thus $\frac{\sigma_s^2}{\sigma_s^2+\sigma_2^2}$ is the fraction of total variance of $y_2$ that is informative about $y_1$. It is almost the correlation coefficient. We put more weight on the additional information $y_2$ whenever it better predicts output $y_1$. This is exactly the informativeness principle: we use a piece of information $y_2$ whenever it helps us better predict output $y_1$.

\end{document}